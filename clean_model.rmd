---
title: "Cleaning and Classifications"
author: 
- Madeline Chang
- Lorena Dorado
- Marvin Moran
date: "6/12/2024"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r, warning=FALSE, message=FALSE}
library(AppliedPredictiveModeling)
library(e1071)
library(caret)
library(rpart)
library(rpart.plot)
library(partykit)
library(earth)
library(kernlab)
library(mlbench)
library(randomForest)
library(dplyr)
library(corrplot)
library(pROC)
library(RANN)
library(glmnet)
library(ggplot2)
library(igraph)
library(tidyverse)
library(gt)
library(RCurl)
```

```{r}
# Read data
url <- "https://github.com/renaqd/team3-ADS503/raw/main/data.csv"
changer_data<- read.csv(url, header = TRUE) %>%
  mutate(Class = as.factor(Class))

```

```{r}
# Check for and remove zero variance predictors
degen<- nearZeroVar(changer_data)
changer_new<- changer_data[,-degen]

# Remove highly correlated variables of 75%
corr<- cor(changer_new[,1:1094])
high_corr <- findCorrelation(corr, cutoff = 0.75)
changer_new<- changer_new[,-high_corr]

# Create vector to store 216 values
# For each column of predictors (1 to 216), calculate skew and store in skewed
skewed<- length(216)
for(i in 1:216){
  skewed[i]<- skewness(changer_new[,i], na.rm = TRUE, type = 1)
}

# See where most of the data falls in range
boxplot(skewed)
```

```{r}
# Group data by class
changer_new %>%
  group_by(Class) %>%
  summarise(n = n()) %>%
  gt::gt()

#write.csv(changer_new, "changer_new.csv", row.names = FALSE)

```

**Exploratory Data Analysis**
```{r}

# data summary
# summary(changer_new)

```

```{r}

colSums(is.na(changer_new))

```

```{r warning=FALSE, message=FALSE, results="hide"}
#| echo: false
# identify numerical features
numerical_features <- changer_new[, sapply(changer_new, is.numeric)]

# print distribution for numerical features to PDF <<-- already done and found in GitHub
pdf("numerical_distributions.pdf")
lapply(names(numerical_features), function(feature) {
    ggplot(changer_new, aes_string(x = feature)) + 
        geom_histogram(bins = 30, fill = "blue", color = "black") + 
        ggtitle(paste("Distribution of", feature))
})
dev.off()

```

```{r}
# corr matrix
cor_matrix <- cor(numerical_features, use = "complete.obs")

# plot correlation matrix
#png("correlation_matrix.png")
#corrplot(cor_matrix, method = "color", type = "upper", order = "hclust", 
         #tl.col = "black", tl.srt = 45)
#dev.off()
```

```{r}

# set threshold for significant correlations
threshold <- 0.75

# create adjacency matrix where correlations above the threshold are marked
adjacency_matrix <- abs(cor_matrix) > threshold

# convert adjacency matrix to graph
graph <- graph.adjacency(adjacency_matrix, mode = "undirected", weighted = TRUE)
E(graph)$weight <- cor_matrix[adjacency_matrix]

# plot the graph
plot(graph, vertex.size = 10, vertex.label.cex = 0.7, edge.width = E(graph)$weight * 2)

```

```{r}

# class distribution <<- code above shows numeric values only, this is a visual
class_distribution <- table(changer_new$Class)
barplot(class_distribution, main = "Class Distribution", col = "cyan",
        xlab = "Class", ylab = "Frequency")

```

**Data Splitting**
```{r}
set.seed(720)

# Create stratified random splits of the data (based on the classes)
trainingRows <- createDataPartition(changer_new$Class, p = .5, list = FALSE) 

# Subset data into train and test
train <- changer_new[trainingRows, ]
test <- changer_new[-trainingRows, ]

# Create control method for cross validation
ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     savePredictions = TRUE)
```

**Model Building Strategies**
```{r warning=FALSE, message=FALSE}
# Function for Training Models
class_function<- function(method){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               metric = "ROC",
               trControl = ctrl)
}

# Function for Training Models with TuneGrids
class_grid<- function(method, grid){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               tuneGrid = grid,
               metric = "ROC",
               trControl = ctrl)
}

# Function for Training Models for Neural Networks
class_nnet<- function(method, grid, maxit){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               tuneGrid = grid,
               maxit = maxit,
               trace = FALSE, 
               metric = "ROC",
               trControl = ctrl)
}

# Function for Training Models with KNN
class_length<- function(method, length){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               tuneLength = length,
               metric = "ROC",
               trControl = ctrl)
}

# Function for Training Models with Bagging
class_bag<- function(method, nbagg){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               nbagg = nbagg,
               metric = "ROC",
               trControl = ctrl)
}

# Function for Training Models with Random Forest
class_rf<- function(method, grid, ntree){
  model<- train(x = train[,1:216], 
               y = train$Class,
               method = method,
               preProc = c("center", "scale"),
               tuneGrid = grid,
               ntree = ntree,
               metric = "ROC",
               trControl = ctrl)
}

```

**Hyper Parameter Tuning Defined in Grids**
```{r warning=FALSE, message=FALSE}
set.seed(720)

# TuneGrid for Penalized Logistic Regrssion
glmnGrid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
                        lambda = seq(.01, .2, length = 10))

# NSC TuneGrid
nsc_grid<- data.frame(threshold = seq(0, 25, length = 30))


# NNET TuneGrid #########################################################
nnet_grid <- expand.grid(size=1:4, decay=c(0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4))

# SVM TuneGrid
sigmaEst <- kernlab::sigest(as.matrix(train[,1:216]))
svmgrid <- expand.grid(sigma = sigmaEst, C = 2^seq(-4,+4))

# RF TuneGrid
mtryValues <- data.frame(mtry = seq(1,10,1))

```

**Train Models**
```{r warning=FALSE, message=FALSE}
#| cache: true

set.seed(720)

# Generalized Linear Model: Logistic Regression
lr<- class_function("glm")

# Linear Discriminant Analysis
lda<- class_function("lda")

# Penalized LR
glmn<- class_grid("glmnet", glmnGrid)

# Nearest Shrunken Centroids
nsc<- class_grid("pam", nsc_grid)

svmR<- class_grid("svmRadial", svmgrid)

# NNET
nnet<- class_nnet("nnet", nnet_grid, 100)

# K Nearest Neighbors
knn<- class_length("knn", 20)

# Bagging
bag<- class_bag("treebag", 50)

# Random Forest
rf<- class_rf("rf", mtryValues, 100)
```

**Model Performance**


```{r, warning=FALSE, message=FALSE}
model_roc <- function(model){
  roc(response = model$pred$obs,
             predictor = model$pred$Changer,
             levels = rev(levels(model$pred$obs)))
}

lrROC <- model_roc(lr)
ldaROC <- model_roc(lda)
glmnROC <- model_roc(glmn)
nscROC <- model_roc(nsc)
svmRROC <- model_roc(svmR)
knnROC <- model_roc(knn)
bagROC <- model_roc(bag)
rfROC <- model_roc(rf)
nnetROC <- model_roc(nnet)


train_re<- resamples(list(
  lr = lr,
  lda = lda,
  glmn = glmn,
  nsc = nsc,
  svmR = svmR,
  knn = knn,
  bag = bag,
  rf = rf,
  nnet = nnet
))

dotplot(train_re, metric = "ROC")

```

**ROC Comparision between models**
```{r, fig.width=8,fig.height=8}
plot(lrROC, type = "s", col = 'red', legacy.axes = TRUE, 
     main = "Molecular Predictors ROC curves")
plot(ldaROC, type = "s", add = TRUE, col = 'green', legacy.axes = TRUE)
plot(glmnROC, type = "s", add = TRUE, col = 'blue', legacy.axes = TRUE)
plot(nscROC, type = "s", add = TRUE, col = 'pink', legacy.axes = TRUE)
plot(svmRROC, type = "s", add = TRUE, col = 'purple', legacy.axes = TRUE)
plot(knnROC, type = "s", add = TRUE, col = 'yellow', legacy.axes = TRUE)
plot(bagROC, type = "s", add = TRUE, col = 'grey', legacy.axes = TRUE)
plot(rfROC, type = "s", add = TRUE, col = 'cyan', legacy.axes = TRUE)
plot(nnetROC , type = "s", add = TRUE, legacy.axes = TRUE)
legend("bottomright", legend=c(paste("LR (AUC =", round(lrROC$auc,4), ")"), 
                               paste("LDA (AUC =", round(ldaROC$auc,4), ")"), 
                               paste("GLMNET (AUC =", round(glmnROC$auc,4), ")"), 
                               paste("NSC (AUC =", round(nscROC$auc,4), ")"), 
                               paste("SVM (AUC =", round(svmRROC$auc,4), ")"), 
                               paste("KNN (AUC =", round(knnROC$auc,4), ")"), 
                               paste("BAG (AUC =", round(bagROC$auc,4), ")"), 
                               paste("RF (AUC =", round(rfROC$auc,4), ")"), 
                               paste("NNET (AUC =", round(nnetROC$auc,4), ")")),
       col=c("red", "green", "blue", "pink", "purple", "yellow", "grey","cyan", "black"), lwd=2)
```


**Top Predictors**
```{r}
lr_Imp <- varImp(lr, scale = FALSE)
glmn_Imp <- varImp(glmn, scale = FALSE)
nsc_Imp <- varImp(nsc, scale = FALSE)
knn_Imp <- varImp(knn, scale = FALSE)

plot(lr_Imp, top = 10)
plot(glmn_Imp, top = 10)
plot(nsc_Imp, top = 10)
plot(knn_Imp, top = 10)
  
# MATS4e, MATS4s match previous research

```

**Shrinking CI**
```{r, warning=FALSE, message=FALSE}
#| cache: true
set.seed(720)
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     savePredictions = TRUE)

# Baseline LR and Selected Models
lr_r<- class_function("glm") # baseline
glmn_r<- class_grid("glmnet", glmnGrid)
nsc_r<- class_grid("pam", nsc_grid)
knn_r<- class_length("knn", 20)
```

**Dot Plot of Selected Models**
```{r, warning=FALSE, message=FALSE}
train_re<- resamples(list(
  lr = lr,
  glmn = glmn,
  nsc = nsc,
  knn = knn
))

dotplot(train_re, metric = "ROC")
```

**ROC of Selected Models**
```{r, fig.width=8,fig.height=8}
lrROC <- model_roc(lr_r)
glmnROC <- model_roc(glmn_r)
nscROC <- model_roc(nsc_r)
knnROC <- model_roc(knn_r)


plot(lrROC, type = "s", col = 'red', legacy.axes = TRUE, 
     main = "Molecular Predictors ROC curves")
plot(glmnROC, type = "s", add = TRUE, col = 'blue', legacy.axes = TRUE)
plot(nscROC, type = "s", add = TRUE, col = 'pink', legacy.axes = TRUE)
plot(knnROC, type = "s", add = TRUE, col = 'yellow', legacy.axes = TRUE)
legend("bottomright", legend=c(paste("LR (AUC =", round(lrROC$auc,4), ")"), 
                               paste("GLMNET (AUC =", round(glmnROC$auc,4), ")"), 
                               paste("NSC (AUC =", round(nscROC$auc,4), ")"), 
                               paste("KNN (AUC =", round(knnROC$auc,4), ")")),
       col=c("red", "blue", "pink", "yellow"), lwd=2)
```

**Compare Repeated Cross Validation Models Using Confusion Matrix**
```{r, warning=FALSE, message=FALSE}
# Create Results table
testResults <- data.frame(
  obs = test$Class,
  lr = predict(lr_r, test[, 1:216]),
  glmnet = predict(glmn_r, test[, 1:216]),
  nsc = predict(nsc_r, test[, 1:216]),
  knn = predict(knn_r, test[, 1:216])
)

selected_models <- c("lr", "glmnet", "nsc", "knn")

# Iterate through model list and create CM per model
for (model in selected_models) {
  cat("Confusion Matrix for", model, ":\n")
  print(confusionMatrix(testResults[[model]], testResults$obs, positive = "Changer"))
  cat("\n")
}
```

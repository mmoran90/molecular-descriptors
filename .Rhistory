library(randomForest)
library(dplyr)
library(corrplot)
library(pROC)
library(RANN)
library(glmnet)
library(ggplot2)
library(igraph)
library(tidyverse)
library(gt)
install.packages("gt")
library(gt)
library(RCurl)
install.packages("gt")
install.packages("gt")
library(RCurl)
install.packages("Rcurl")
install.packages("RCurl")
library(RCurl)
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
# Read data
url <- "https://github.com/renaqd/team3-ADS503/raw/main/data.csv"
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
# Read data
url <- read.csv("data.csv")
# Read data
url <- read.csv("data.csv")
# Read data
url <- read.csv("data.csv")
setwd("C:/Users/marvi/GitHub Projects/team3-ADS503")
# Read data
url <- read.csv("data.csv")
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
# Read data
url <- "https://github.com/renaqd/team3-ADS503/raw/main/data.csv"
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
library(dplyr)
# Read data
url <- "https://github.com/renaqd/team3-ADS503/raw/main/data.csv"
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
# Chunk 1
library(AppliedPredictiveModeling)
library(e1071)
library(caret)
library(rpart)
library(rpart.plot)
library(partykit)
library(earth)
library(kernlab)
library(mlbench)
library(randomForest)
library(dplyr)
library(corrplot)
library(pROC)
library(RANN)
library(glmnet)
library(ggplot2)
library(igraph)
library(tidyverse)
library(gt)
library(RCurl)
# Chunk 2
# Read data
url <- "https://github.com/renaqd/team3-ADS503/raw/main/data.csv"
changer_data<- read.csv(url, header = TRUE) %>%
mutate(Class = as.factor(Class))
# Chunk 3
# Check for and remove zero variance predictors
degen<- nearZeroVar(changer_data)
changer_new<- changer_data[,-degen]
# Remove highly correlated variables of 75%
corr<- cor(changer_new[,1:1094])
high_corr <- findCorrelation(corr, cutoff = 0.75)
changer_new<- changer_new[,-high_corr]
# Create vector to store 216 values
# For each column of predictors (1 to 216), calculate skew and store in skewed
skewed<- length(216)
for(i in 1:216){
skewed[i]<- skewness(changer_new[,i], na.rm = TRUE, type = 1)
}
# See where most of the data falls in range
boxplot(skewed)
# Chunk 4
# Group data by class
changer_new %>%
group_by(Class) %>%
summarise(n = n()) %>%
gt::gt()
#write.csv(changer_new, "changer_new.csv", row.names = FALSE)
# Chunk 5
# data summary
# summary(changer_new)
# Chunk 6
colSums(is.na(changer_new))
# Chunk 7
#| echo: false
# identify numerical features
numerical_features <- changer_new[, sapply(changer_new, is.numeric)]
# print distribution for numerical features to PDF <<-- already done and found in GitHub
pdf("numerical_distributions.pdf")
lapply(names(numerical_features), function(feature) {
ggplot(changer_new, aes_string(x = feature)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
ggtitle(paste("Distribution of", feature))
})
dev.off()
# Chunk 8
# corr matrix
cor_matrix <- cor(numerical_features, use = "complete.obs")
# plot correlation matrix
#png("correlation_matrix.png")
#corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
#tl.col = "black", tl.srt = 45)
#dev.off()
# Chunk 9
# set threshold for significant correlations
threshold <- 0.75
# create adjacency matrix where correlations above the threshold are marked
adjacency_matrix <- abs(cor_matrix) > threshold
# convert adjacency matrix to graph
graph <- graph.adjacency(adjacency_matrix, mode = "undirected", weighted = TRUE)
E(graph)$weight <- cor_matrix[adjacency_matrix]
# plot the graph
plot(graph, vertex.size = 10, vertex.label.cex = 0.7, edge.width = E(graph)$weight * 2)
# Chunk 10
# class distribution <<- code above shows numeric values only, this is a visual
class_distribution <- table(changer_new$Class)
barplot(class_distribution, main = "Class Distribution", col = "cyan",
xlab = "Class", ylab = "Frequency")
# Chunk 11
set.seed(720)
# Create stratified random splits of the data (based on the classes)
trainingRows <- createDataPartition(changer_new$Class, p = .5, list = FALSE)
# Subset data into train and test
train <- changer_new[trainingRows, ]
test <- changer_new[-trainingRows, ]
# Create control method for cross validation
ctrl <- trainControl(method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Chunk 12
# Function for Training Models
class_function<- function(method){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl)
}
# Function for Training Models with TuneGrids
class_grid<- function(method, grid){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
tuneGrid = grid,
metric = "ROC",
trControl = ctrl)
}
# Function for Training Models for Neural Networks
class_nnet<- function(method, grid, maxit){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
tuneGrid = grid,
maxit = maxit,
trace = FALSE,
metric = "ROC",
trControl = ctrl)
}
# Function for Training Models with KNN
class_length<- function(method, length){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
tuneLength = length,
metric = "ROC",
trControl = ctrl)
}
# Function for Training Models with Bagging
class_bag<- function(method, nbagg){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
nbagg = nbagg,
metric = "ROC",
trControl = ctrl)
}
# Function for Training Models with Random Forest
class_rf<- function(method, grid, ntree){
model<- train(x = train[,1:216],
y = train$Class,
method = method,
preProc = c("center", "scale"),
tuneGrid = grid,
ntree = ntree,
metric = "ROC",
trControl = ctrl)
}
# Chunk 13
set.seed(720)
# TuneGrid for Penalized Logistic Regrssion
glmnGrid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
lambda = seq(.01, .2, length = 10))
# NSC TuneGrid
nsc_grid<- data.frame(threshold = seq(0, 25, length = 30))
# NNET TuneGrid #########################################################
nnet_grid <- expand.grid(size=1:4, decay=c(0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4))
# SVM TuneGrid
sigmaEst <- kernlab::sigest(as.matrix(train[,1:216]))
svmgrid <- expand.grid(sigma = sigmaEst, C = 2^seq(-4,+4))
# RF TuneGrid
mtryValues <- data.frame(mtry = seq(1,10,1))
# Chunk 14
#| cache: true
set.seed(720)
# Generalized Linear Model: Logistic Regression
lr<- class_function("glm")
# Linear Discriminant Analysis
lda<- class_function("lda")
# Penalized LR
glmn<- class_grid("glmnet", glmnGrid)
# Nearest Shrunken Centroids
nsc<- class_grid("pam", nsc_grid)
svmR<- class_grid("svmRadial", svmgrid)
# NNET
nnet<- class_nnet("nnet", nnet_grid, 100)
# K Nearest Neighbors
knn<- class_length("knn", 20)
# Bagging
bag<- class_bag("treebag", 50)
# Random Forest
rf<- class_rf("rf", mtryValues, 100)
# Chunk 15
model_roc <- function(model){
roc(response = model$pred$obs,
predictor = model$pred$Changer,
levels = rev(levels(model$pred$obs)))
}
lrROC <- model_roc(lr)
ldaROC <- model_roc(lda)
glmnROC <- model_roc(glmn)
nscROC <- model_roc(nsc)
svmRROC <- model_roc(svmR)
knnROC <- model_roc(knn)
bagROC <- model_roc(bag)
rfROC <- model_roc(rf)
nnetROC <- model_roc(nnet)
train_re<- resamples(list(
lr = lr,
lda = lda,
glmn = glmn,
nsc = nsc,
svmR = svmR,
knn = knn,
bag = bag,
rf = rf,
nnet = nnet
))
dotplot(train_re, metric = "ROC")
# Chunk 16
plot(lrROC, type = "s", col = 'red', legacy.axes = TRUE,
main = "Molecular Predictors ROC curves")
plot(ldaROC, type = "s", add = TRUE, col = 'green', legacy.axes = TRUE)
plot(glmnROC, type = "s", add = TRUE, col = 'blue', legacy.axes = TRUE)
plot(nscROC, type = "s", add = TRUE, col = 'pink', legacy.axes = TRUE)
plot(svmRROC, type = "s", add = TRUE, col = 'purple', legacy.axes = TRUE)
plot(knnROC, type = "s", add = TRUE, col = 'yellow', legacy.axes = TRUE)
plot(bagROC, type = "s", add = TRUE, col = 'grey', legacy.axes = TRUE)
plot(rfROC, type = "s", add = TRUE, col = 'cyan', legacy.axes = TRUE)
plot(nnetROC , type = "s", add = TRUE, legacy.axes = TRUE)
legend("bottomright", legend=c(paste("LR (AUC =", round(lrROC$auc,4), ")"),
paste("LDA (AUC =", round(ldaROC$auc,4), ")"),
paste("GLMNET (AUC =", round(glmnROC$auc,4), ")"),
paste("NSC (AUC =", round(nscROC$auc,4), ")"),
paste("SVM (AUC =", round(svmRROC$auc,4), ")"),
paste("KNN (AUC =", round(knnROC$auc,4), ")"),
paste("BAG (AUC =", round(bagROC$auc,4), ")"),
paste("RF (AUC =", round(rfROC$auc,4), ")"),
paste("NNET (AUC =", round(nnetROC$auc,4), ")")),
col=c("red", "green", "blue", "pink", "purple", "yellow", "grey","cyan", "black"), lwd=2)
# Chunk 17
lr_Imp <- varImp(lr, scale = FALSE)
glmn_Imp <- varImp(glmn, scale = FALSE)
nsc_Imp <- varImp(nsc, scale = FALSE)
knn_Imp <- varImp(knn, scale = FALSE)
plot(lr_Imp, top = 10)
plot(glmn_Imp, top = 10)
plot(nsc_Imp, top = 10)
plot(knn_Imp, top = 10)
# MATS4e, MATS4s match previous research
# Chunk 18
#| cache: true
set.seed(720)
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Baseline LR and Selected Models
lr_r<- class_function("glm") # baseline
glmn_r<- class_grid("glmnet", glmnGrid)
nsc_r<- class_grid("pam", nsc_grid)
knn_r<- class_length("knn", 20)
# Chunk 19
train_re<- resamples(list(
lr = lr_r,
glmn = glmn_r,
nsc = nsc_r,
knn = knn_r
))
dotplot(train_re, metric = "ROC")
# Chunk 20
lrROC <- model_roc(lr_r)
glmnROC <- model_roc(glmn_r)
nscROC <- model_roc(nsc_r)
knnROC <- model_roc(knn_r)
plot(lrROC, type = "s", col = 'red', legacy.axes = TRUE,
main = "Molecular Predictors ROC curves")
plot(glmnROC, type = "s", add = TRUE, col = 'blue', legacy.axes = TRUE)
plot(nscROC, type = "s", add = TRUE, col = 'pink', legacy.axes = TRUE)
plot(knnROC, type = "s", add = TRUE, col = 'yellow', legacy.axes = TRUE)
legend("bottomright", legend=c(paste("LR (AUC =", round(lrROC$auc,4), ")"),
paste("GLMNET (AUC =", round(glmnROC$auc,4), ")"),
paste("NSC (AUC =", round(nscROC$auc,4), ")"),
paste("KNN (AUC =", round(knnROC$auc,4), ")")),
col=c("red", "blue", "pink", "yellow"), lwd=2)
# Chunk 21
# Create Results table
testResults <- data.frame(
obs = test$Class,
lr = predict(lr_r, test[, 1:216]),
glmnet = predict(glmn_r, test[, 1:216]),
nsc = predict(nsc_r, test[, 1:216]),
knn = predict(knn_r, test[, 1:216])
)
selected_models <- c("lr", "glmnet", "nsc", "knn")
# Iterate through model list and create CM per model
for (model in selected_models) {
cat("Confusion Matrix for", model, ":\n")
print(confusionMatrix(testResults[[model]], testResults$obs, positive = "Changer"))
cat("\n")
}
# data summary
summary(changer_new)
colSums(is.na(changer_new))
#| echo: false
# identify numerical features
numerical_features <- changer_new[, sapply(changer_new, is.numeric)]
# corr matrix
cor_matrix <- cor(numerical_features, use = "complete.obs")
# set threshold for significant correlations
threshold <- 0.75
# create adjacency matrix where correlations above the threshold are marked
adjacency_matrix <- abs(cor_matrix) > threshold
# convert adjacency matrix to graph
graph <- graph.adjacency(adjacency_matrix, mode = "undirected", weighted = TRUE)
E(graph)$weight <- cor_matrix[adjacency_matrix]
# plot the graph
plot(graph, vertex.size = 10, vertex.label.cex = 0.7, edge.width = E(graph)$weight * 2)
barplot(class_distribution, main = "Class Distribution", col = ("blue", "red"),
xlab = "Class", ylab = "Frequency")
# data summary
summary(changer_new)
library(reshape2)
#
# subset predictors with high variability
selected_vars <- c("VR2_Dt", "GATS1c", "BCUTp.1l", "BCUTp.1h", "topoDiameter",
"AATS8p", "MDEC.22", "MDEC.23")
# Create a subset of the data with selected variables
subset_data <- changer_data %>% select(all_of(selected_vars))
# calculate the correlation matrix for the subset
subset_cor_matrix <- cor(subset_data, use = "complete.obs")
# visualize using corrplot
corrplot(subset_cor_matrix, method = "color", type = "upper",
order = "hclust", tl.col = "black", tl.cex = 0.8)
# visualize using ggplot2
melted_subset_cor_matrix <- melt(subset_cor_matrix)
ggplot(data = melted_subset_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 7, hjust = 1)) +
coord_fixed()
# histograms
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
# density plots
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value, fill = variable)) +
geom_density(alpha = 0.5) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
# box Plots
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = variable, y = value)) +
geom_boxplot(fill = "blue", color = "black", alpha = 0.7) +
theme_minimal()
# scatter Plot Matrix
pairs(subset_data, pch = 21, bg = c("red", "green3", "blue")[changer_data$Class])
# histograms
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
# IQR method
outliers <- apply(subset_data, 2, function(x) {
Q1 <- quantile(x, 0.25)
Q3 <- quantile(x, 0.75)
IQR <- Q3 - Q1
x < (Q1 - 1.5 * IQR) | x > (Q3 + 1.5 * IQR)
})
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
# histograms
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
subset_data <- changer_data %>% select(all_of(selected_vars))
# calculate the correlation matrix for the subset
subset_cor_matrix <- cor(subset_data, use = "complete.obs")
# visualize using ggplot2
melted_subset_cor_matrix <- melt(subset_cor_matrix)
ggplot(data = melted_subset_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 7, hjust = 1)) +
coord_fixed()
# histograms
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
# subset predictors with high variability
selected_vars <- c("VR2_Dt", "GATS1c", "BCUTp.1l", "BCUTp.1h", "topoDiameter",
"AATS8p", "MDEC.22", "MDEC.23")
subset_data <- changer_data %>% select(all_of(selected_vars))
# calculate the correlation matrix for the subset
subset_cor_matrix <- cor(subset_data, use = "complete.obs")
# visualize using ggplot2
melted_subset_cor_matrix <- melt(subset_cor_matrix)
ggplot(data = melted_subset_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 7, hjust = 1)) +
coord_fixed()
ggplot(data = melted_subset_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 7, hjust = 1)) +
coord_fixed()
# calculate the correlation matrix for the subset
subset_cor_matrix <- cor(subset_data, use = "complete.obs")
# visualize using ggplot2
melted_subset_cor_matrix <- melt(subset_cor_matrix)
ggplot(data = melted_subset_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 7, hjust = 1)) +
coord_fixed()
# histograms
subset_data %>%
gather(key = "variable", value = "value") %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black", alpha = 0.7) +
facet_wrap(~ variable, scales = "free") +
theme_minimal()
